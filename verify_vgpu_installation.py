#!/usr/bin/env python3
"""
Final vGPU Installation Verification and Summary Report
======================================================

This script verifies the complete vGPU installation and benchmarking results
providing a final summary of all real testing performed.
"""

import json
import os
from pathlib import Path
from datetime import datetime

def verify_installation_and_benchmarks():
    """Verify installation and benchmarks with comprehensive summary"""
    
    print("üîç FINAL vGPU v1.6 INSTALLATION & BENCHMARK VERIFICATION")
    print("=" * 70)
    print()
    
    # Check installation directory
    install_dir = Path.home() / "vgpu_v16_real"
    benchmark_dir = Path("benchmarks") / "real_installation"
    
    print("üìÅ INSTALLATION VERIFICATION:")
    print("-" * 40)
    
    if install_dir.exists():
        print(f"‚úÖ Installation Directory: {install_dir}")
        
        # Check core components
        components = {
            'vGPU Core': install_dir / "vgpu_v16",
            'Enhanced Engine': install_dir / "enhanced_performance_engine.py",
            'Ultra Engine': install_dir / "ultra_performance_engine.py",
            'System Launcher': install_dir / "launch_vgpu.py",
            'Device Registry': install_dir / "device_registry.json",
            'Environment Script': install_dir / "vgpu_env.sh",
            'Service Config': install_dir / "vgpu-v16.service"
        }
        
        for component_name, component_path in components.items():
            if component_path.exists():
                if component_path.is_dir():
                    file_count = len(list(component_path.rglob('*')))
                    print(f"  ‚úÖ {component_name}: {file_count} files")
                else:
                    size_kb = component_path.stat().st_size / 1024
                    print(f"  ‚úÖ {component_name}: {size_kb:.1f} KB")
            else:
                print(f"  ‚ùå {component_name}: Missing")
                
        total_size_mb = sum(f.stat().st_size for f in install_dir.rglob('*') if f.is_file()) / (1024*1024)
        print(f"  üìä Total Installation Size: {total_size_mb:.1f} MB")
        
    else:
        print("‚ùå Installation directory not found")
        return False
    
    print()
    
    # Check benchmark results
    print("üìä BENCHMARK VERIFICATION:")
    print("-" * 40)
    
    if benchmark_dir.exists():
        print(f"‚úÖ Benchmark Directory: {benchmark_dir}")
        
        # Find latest benchmark results
        result_files = list(benchmark_dir.glob("real_benchmark_results_*.json"))
        report_files = list(benchmark_dir.glob("comprehensive_report_*.txt"))
        
        if result_files:
            latest_results = max(result_files, key=lambda f: f.stat().st_mtime)
            print(f"  ‚úÖ Latest Results: {latest_results.name}")
            
            try:
                with open(latest_results, 'r') as f:
                    results = json.load(f)
                
                # CPU Benchmarks
                cpu_benchmarks = results.get('cpu_benchmarks', {})
                if cpu_benchmarks:
                    print(f"  üñ•Ô∏è  CPU Matrix Mult: {cpu_benchmarks.get('matrix_multiplication', {}).get('gflops', 0):.1f} GFLOPS")
                    print(f"  üñ•Ô∏è  CPU FFT: {cpu_benchmarks.get('fft_computation', {}).get('mops', 0):.1f} MOPS")
                    print(f"  üñ•Ô∏è  CPU 3D Graphics: {cpu_benchmarks.get('3d_graphics', {}).get('vertices_per_second', 0):,.0f} vertices/sec")
                
                # GPU Benchmarks
                gpu_benchmarks = results.get('gpu_benchmarks', {})
                gpu_available = gpu_benchmarks.get('available', False)
                print(f"  üéÆ GPU Available: {'Yes' if gpu_available else 'No'}")
                if gpu_available:
                    for bench_name, bench_data in gpu_benchmarks.get('benchmarks', {}).items():
                        print(f"  üéÆ GPU {bench_name}: {bench_data.get('time_seconds', 0):.3f}s")
                
                # Quantum Benchmarks
                quantum_benchmarks = results.get('quantum_benchmarks', {})
                quantum_available = quantum_benchmarks.get('available', False)
                print(f"  ‚öõÔ∏è  Quantum Available: {'Yes' if quantum_available else 'No'}")
                if quantum_available:
                    backend = quantum_benchmarks.get('backend', 'unknown')
                    print(f"  ‚öõÔ∏è  Quantum Backend: {backend}")
                
                # vGPU Benchmarks
                vgpu_benchmarks = results.get('vgpu_benchmarks', {})
                vgpu_available = vgpu_benchmarks.get('available', False)
                if vgpu_available:
                    max_speedup = vgpu_benchmarks.get('maximum_speedup', 0)
                    avg_speedup = vgpu_benchmarks.get('average_speedup', 0)
                    target_achieved = vgpu_benchmarks.get('minimum_target_achieved', False)
                    
                    print(f"  üöÄ vGPU Maximum Speedup: {max_speedup:,.0f}x")
                    print(f"  üöÄ vGPU Average Speedup: {avg_speedup:,.0f}x")
                    print(f"  üöÄ 2000x Target: {'‚úÖ ACHIEVED' if target_achieved else '‚ùå FAILED'}")
                    
                    workloads = vgpu_benchmarks.get('performance_results', {}).get('workloads', {})
                    print(f"  üöÄ Workloads Tested: {len(workloads)}")
                    
                    for workload_name, workload_data in workloads.items():
                        speedup = workload_data.get('mathematical_speedup', 0)
                        method = workload_data.get('method', 'unknown')
                        print(f"    ‚Ä¢ {workload_name.title()}: {speedup:,.0f}x ({method})")
                else:
                    print("  ‚ùå vGPU benchmarks failed")
                
            except Exception as e:
                print(f"  ‚ùå Error reading results: {e}")
        else:
            print("  ‚ùå No benchmark result files found")
            
        if report_files:
            latest_report = max(report_files, key=lambda f: f.stat().st_mtime)
            print(f"  ‚úÖ Latest Report: {latest_report.name}")
            
    else:
        print("‚ùå Benchmark directory not found")
    
    print()
    
    # Performance Summary
    print("üèÜ PERFORMANCE SUMMARY:")
    print("-" * 40)
    
    try:
        if result_files:
            with open(latest_results, 'r') as f:
                results = json.load(f)
            
            # Extract key metrics
            cpu_gflops = results.get('cpu_benchmarks', {}).get('matrix_multiplication', {}).get('gflops', 0)
            vgpu_max_speedup = results.get('vgpu_benchmarks', {}).get('maximum_speedup', 0)
            vgpu_target = results.get('vgpu_benchmarks', {}).get('minimum_target_achieved', False)
            
            print(f"Baseline CPU Performance: {cpu_gflops:.1f} GFLOPS")
            print(f"vGPU Maximum Speedup: {vgpu_max_speedup:,.0f}x")
            print(f"Performance Target (2000x): {'‚úÖ ACHIEVED' if vgpu_target else '‚ùå FAILED'}")
            
            if vgpu_target:
                print(f"Performance Ratio: {vgpu_max_speedup/2000:.1f}x above minimum target")
            
            # System specs
            system_specs = results.get('system_specs', {})
            cpu_info = system_specs.get('cpu', {})
            memory_info = system_specs.get('memory', {})
            
            print(f"Test Hardware: {cpu_info.get('cores_physical', 0)} cores, {memory_info.get('total_gb', 0):.1f}GB RAM")
            print(f"Test Platform: {system_specs.get('platform', {}).get('os', 'Unknown')} {system_specs.get('platform', {}).get('python_version', '')}")
    except:
        print("Unable to generate performance summary")
    
    print()
    
    # Final verification status
    print("üéØ FINAL VERIFICATION STATUS:")
    print("-" * 40)
    
    verification_checks = [
        ("vGPU Installation", install_dir.exists()),
        ("Core Components", (install_dir / "vgpu_v16").exists()),
        ("Performance Engines", (install_dir / "enhanced_performance_engine.py").exists()),
        ("Benchmark Results", len(result_files) > 0 if benchmark_dir.exists() else False),
        ("Comprehensive Report", len(report_files) > 0 if benchmark_dir.exists() else False)
    ]
    
    # Check vGPU performance
    vgpu_performance_ok = False
    try:
        if result_files:
            with open(latest_results, 'r') as f:
                results = json.load(f)
            vgpu_performance_ok = results.get('vgpu_benchmarks', {}).get('minimum_target_achieved', False)
    except:
        pass
    
    verification_checks.append(("vGPU Performance (2000x+)", vgpu_performance_ok))
    
    all_passed = True
    for check_name, check_result in verification_checks:
        status = "‚úÖ PASS" if check_result else "‚ùå FAIL"
        print(f"{status} {check_name}")
        if not check_result:
            all_passed = False
    
    print()
    if all_passed:
        print("üéâ VERIFICATION COMPLETE: ALL TESTS PASSED")
        print("vGPU v1.6 installation and benchmarking successful!")
        print("Ready for production use with verified 2000x+ speedup.")
    else:
        print("‚ö†Ô∏è  VERIFICATION INCOMPLETE: Some tests failed")
        print("Review failed checks above for details.")
    
    print()
    print("=" * 70)
    print(f"Verification completed at: {datetime.now().isoformat()}")
    print("=" * 70)
    
    return all_passed

if __name__ == "__main__":
    success = verify_installation_and_benchmarks()
    exit(0 if success else 1)